{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8537b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c4ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1db5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0b85b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Card Type</th>\n",
       "      <th>Point Earned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  Complain  \\\n",
       "0          1               1        101348.88       1         1   \n",
       "1          0               1        112542.58       0         1   \n",
       "2          1               0        113931.57       1         1   \n",
       "3          0               0         93826.63       0         0   \n",
       "4          1               1         79084.10       0         0   \n",
       "\n",
       "   Satisfaction Score Card Type  Point Earned  \n",
       "0                   2   DIAMOND           464  \n",
       "1                   3   DIAMOND           456  \n",
       "2                   3   DIAMOND           377  \n",
       "3                   5      GOLD           350  \n",
       "4                   5      GOLD           425  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('notebook/data/Customer-Churn-Records.csv')\n",
    "df.drop(columns=['RowNumber','CustomerId','Surname'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a1c995",
   "metadata": {},
   "source": [
    "### creating the preprocessor object and data transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bb8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessor_object():\n",
    "    num_pipeline_scaling = Pipeline(steps=[\n",
    "        ('imputer',SimpleImputer(strategy='mean')),\n",
    "        ('scaler',StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    cat_pipeline = Pipeline(steps=[\n",
    "        ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "        ('one_hot_encoding',OneHotEncoder(sparse=False)),\n",
    "        ('scaler',StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    num_pipeline_missing = Pipeline(steps=[\n",
    "        ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "        ('scaler',StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    num_columns_scaling = ['CreditScore','Age','Balance','EstimatedSalary']\n",
    "    num_columns_missing = ['Tenure','NumOfProducts','HasCrCard','IsActiveMember','Complain','EstimatedSalary','Satisfaction Score']\n",
    "    cat_columns = ['Geography','Gender','Card Type']\n",
    "    \n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            ('num_columns_missing',num_pipeline_missing, num_columns_missing),\n",
    "            ('num_columns_scaling',num_pipeline_scaling,num_columns_scaling),\n",
    "            ('cat_columns',cat_pipeline, cat_columns)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99cb0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_data(train_df, test_df):\n",
    "    train_input_features = train_df.drop(columns=['Exited'])\n",
    "    test_input_features = test_df.drop(columns=['Exited'])\n",
    "    \n",
    "    \n",
    "    preprocessor = get_preprocessor_object()\n",
    "    \n",
    "    train_input_features_arr = preprocessor.fit_transform(train_input_features)\n",
    "    test_input_features_arr = preprocessor.transform(test_input_features)\n",
    "    \n",
    "    target_column = 'Exited'\n",
    "    train_target = train_df[target_column]\n",
    "    test_target = test_df[target_column]\n",
    "    \n",
    "    train_features_arr = np.c_[\n",
    "        train_input_features_arr,np.array(train_target)\n",
    "    ]\n",
    "    \n",
    "    test_features_arr = np.c_[\n",
    "        test_input_features_arr, np.array(test_target)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    return train_features_arr, test_features_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "558c558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , test_df = train_test_split(df, test_size=0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22948cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    6355\n",
      "1    1645\n",
      "Name: count, dtype: int64\n",
      "Exited\n",
      "0    1607\n",
      "1     393\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Exited'].value_counts())\n",
    "print(test_df['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00482bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sande\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_arr , test_arr = get_transformed_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa005fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 21)\n",
      "(2000, 21)\n"
     ]
    }
   ],
   "source": [
    "print(train_arr.shape)\n",
    "print(test_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d575ee7",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4469f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (\n",
    "    train_arr[:,:-1],\n",
    "    test_arr[:,:-1],\n",
    "    \n",
    "    train_arr[:,-1],\n",
    "    test_arr[:,-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09a385bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict ={\n",
    "    'logistic_regression':LogisticRegression(),\n",
    "    'decision_tree':DecisionTreeClassifier(),\n",
    "    'random_forest':RandomForestClassifier(),\n",
    "    'svm':SVC(),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'gradient_boosting':GradientBoostingClassifier(),\n",
    "    'xgboost':XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d84d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, X_test, y_train, y_test, models):\n",
    "    report = {}\n",
    "    \n",
    "    for i in range (len(models)):\n",
    "        model = list(models.values())[i]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        training_accuracy = accuracy_score(y_train,y_pred_train)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        precision = precision_score(y_test, y_pred_test)\n",
    "        recall = recall_score(y_test, y_pred_test)\n",
    "        f1score = f1_score(y_test, y_pred_test)\n",
    "        \n",
    "        report[list(models.keys())[i]] = [training_accuracy,test_accuracy,precision,recall,f1score]\n",
    "    \n",
    "    report_df = pd.DataFrame.from_dict(data=report,orient='index').reset_index()\n",
    "    report_df.rename(columns={\n",
    "        'index':'models',\n",
    "        0:'training_accuracy',\n",
    "        1:'test_accuracy',\n",
    "        2:'f1_score',\n",
    "        3:'precision',\n",
    "        4:'recall'\n",
    "    },inplace=True)\n",
    "        \n",
    "    return report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2110067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.994885</td>\n",
       "      <td>0.989822</td>\n",
       "      <td>0.992347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.993875</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931298</td>\n",
       "      <td>0.964427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.996188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                models  training_accuracy  test_accuracy  f1_score  precision  \\\n",
       "0  logistic_regression           0.998500         0.9990  0.997455   0.997455   \n",
       "1        decision_tree           1.000000         0.9970  0.994885   0.989822   \n",
       "2        random_forest           1.000000         0.9990  0.997455   0.997455   \n",
       "3                  svm           0.998500         0.9990  0.997455   0.997455   \n",
       "4                  KNN           0.993875         0.9865  1.000000   0.931298   \n",
       "5    gradient_boosting           0.999500         0.9985  0.994924   0.997455   \n",
       "6              xgboost           0.999875         0.9990  0.997455   0.997455   \n",
       "\n",
       "     recall  \n",
       "0  0.997455  \n",
       "1  0.992347  \n",
       "2  0.997455  \n",
       "3  0.997455  \n",
       "4  0.964427  \n",
       "5  0.996188  \n",
       "6  0.997455  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = evaluate_models(X_train,X_test, y_train, y_test , models_dict)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0bf33",
   "metadata": {},
   "source": [
    "**Note**\n",
    "- In the data Complain feature is very highly correlated with Exited so it contributes about more than 15% of the model accuracy\n",
    "- when standard scaler is applied in all the columns , non tree based algorithms are also performing well\n",
    "- without standard scaler the Logistic regression, KNN and SVM were not performing well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0fde05",
   "metadata": {},
   "source": [
    "### logistic regression , KNN and SVM are not performing well  (without standard scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d5c0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.794375</td>\n",
       "      <td>0.8035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.994885</td>\n",
       "      <td>0.989822</td>\n",
       "      <td>0.992347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.794375</td>\n",
       "      <td>0.8035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.811375</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.073791</td>\n",
       "      <td>0.107807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.996188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                models  training_accuracy  test_accuracy  f1_score  precision  \\\n",
       "0  logistic_regression           0.794375         0.8035  0.000000   0.000000   \n",
       "1        decision_tree           1.000000         0.9970  0.994885   0.989822   \n",
       "2        random_forest           1.000000         0.9990  0.997455   0.997455   \n",
       "3                  svm           0.794375         0.8035  0.000000   0.000000   \n",
       "4                  KNN           0.811375         0.7600  0.200000   0.073791   \n",
       "5    gradient_boosting           0.999500         0.9985  0.994924   0.997455   \n",
       "6              xgboost           0.999875         0.9990  0.997455   0.997455   \n",
       "\n",
       "     recall  \n",
       "0  0.000000  \n",
       "1  0.992347  \n",
       "2  0.997455  \n",
       "3  0.000000  \n",
       "4  0.107807  \n",
       "5  0.996188  \n",
       "6  0.997455  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('notebook/data/without_scaling.csv').drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fdfea1",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- logistic regression precision and recall are zero because the true positive is zero\n",
    "- It is not being able to classify True positive correctly because data might mostly contain the non linear relationship and  logistic regression is limited to capturing linear relationships between features and the target variable\n",
    "- similarly there is also problem of difference in scale in the data i.e why these algorithms are not performing well compared to that of tree based algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf609b",
   "metadata": {},
   "source": [
    "### Models doesnot perform well without Complain feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ccded25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.811375</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>0.565517</td>\n",
       "      <td>0.208651</td>\n",
       "      <td>0.304833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.508906</td>\n",
       "      <td>0.486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.447837</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.371501</td>\n",
       "      <td>0.500858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.858250</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.279898</td>\n",
       "      <td>0.379965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0.873625</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0.473282</td>\n",
       "      <td>0.577640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.968375</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.524173</td>\n",
       "      <td>0.589413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                models  training_accuracy  test_accuracy  f1_score  precision  \\\n",
       "0  logistic_regression           0.811375         0.8130  0.565517   0.208651   \n",
       "1        decision_tree           1.000000         0.7885  0.465116   0.508906   \n",
       "2        random_forest           1.000000         0.8640  0.761905   0.447837   \n",
       "3                  svm           0.866500         0.8545  0.768421   0.371501   \n",
       "4                  KNN           0.858250         0.8205  0.591398   0.279898   \n",
       "5    gradient_boosting           0.873625         0.8640  0.741036   0.473282   \n",
       "6              xgboost           0.968375         0.8565  0.673203   0.524173   \n",
       "\n",
       "     recall  \n",
       "0  0.304833  \n",
       "1  0.486027  \n",
       "2  0.564103  \n",
       "3  0.500858  \n",
       "4  0.379965  \n",
       "5  0.577640  \n",
       "6  0.589413  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('notebook/data/without_Complain.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a30a16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models_dict['gradient_boosting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f61afa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69539349,  0.80843615, -1.54035103, ...,  1.73262835,\n",
       "        -0.58023704, -0.57388614],\n",
       "       [-1.38944225,  0.80843615,  0.64920267, ..., -0.57715782,\n",
       "        -0.58023704,  1.74250594],\n",
       "       [-0.3483691 ,  0.80843615,  0.64920267, ...,  1.73262835,\n",
       "        -0.58023704, -0.57388614],\n",
       "       ...,\n",
       "       [ 0.69270405, -0.91668767,  0.64920267, ..., -0.57715782,\n",
       "         1.72343359, -0.57388614],\n",
       "       [-0.3483691 , -0.91668767,  0.64920267, ..., -0.57715782,\n",
       "         1.72343359, -0.57388614],\n",
       "       [-1.38944225, -0.91668767,  0.64920267, ..., -0.57715782,\n",
       "        -0.58023704,  1.74250594]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a87e1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3483691 ,  0.80843615,  0.64920267, -1.02583358, -0.50994211,\n",
       "        -0.72797953, -1.43218616, -0.52560743,  0.48508334, -1.21847056,\n",
       "        -0.72797953, -0.99850112, -0.57946723,  1.73494238,  1.09499335,\n",
       "        -1.09499335, -0.57812007,  1.73262835, -0.58023704, -0.57388614]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c305f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(model.predict(X_test[100].reshape(1,-1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "091e3e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'log_loss',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760821e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
